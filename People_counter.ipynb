{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIhbp8fn9Oq9",
        "outputId": "382caa30-453c-41c1-c54b-fa09ae817a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics supervision opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhTxVD77C_1G",
        "outputId": "b736486c-33fd-4b4a-d2c8-d116ed69f85f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.246-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.246-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supervision-0.27.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: supervision, ultralytics-thop, ultralytics\n",
            "Successfully installed supervision-0.27.0 ultralytics-8.3.246 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPqJp6ydi6VH",
        "outputId": "71d65be9-4334-49bc-bc17-88c329de1d25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: ultralytics\n",
            "Version: 8.3.246\n",
            "Summary: Ultralytics YOLO üöÄ for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\n",
            "Home-page: https://ultralytics.com\n",
            "Author: \n",
            "Author-email: Glenn Jocher <glenn.jocher@ultralytics.com>, Jing Qiu <jing.qiu@ultralytics.com>\n",
            "License: AGPL-3.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: matplotlib, numpy, opencv-python, pillow, polars, psutil, pyyaml, requests, scipy, torch, torchvision, ultralytics-thop\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnDxIZ5SkU17",
        "outputId": "fe6071cc-45db-4e84-fe6d-5b01054e8a54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import argparse\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "#import numpy as np\n",
        "#import torch\n",
        "\n",
        "def main():\n",
        "\n",
        "\n",
        "    frame_width, frame_height = 640, 360\n",
        "\n",
        "   # cap = cv2.VideoCapture(0)\n",
        "    video_path = \"/content/drive/MyDrive/Colab Notebooks/video/video1.mp4\"\n",
        "    OUTPUT_PATH = \"/content/drive/MyDrive/Colab Notebooks/video/output.mp4\"  # Output video path\n",
        "    cap=cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "      raise Exception(f\"Cannot open video: {video_path}\")\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
        "\n",
        "    # Video writer to save output\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, 30, (frame_width, frame_height))\n",
        "    PERSON_CLASS_ID = 0\n",
        "    prev_time = 0\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "    box_annotator = sv.BoxAnnotator(\n",
        "         thickness=2,\n",
        "         color=sv.Color(0,255,0)\n",
        "    )\n",
        "\n",
        "    label_annotator = sv.LabelAnnotator(\n",
        "    text_scale=0.3,\n",
        "    text_thickness=1,\n",
        "    text_color=sv.Color.RED,\n",
        "    text_padding=1\n",
        ")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame is None:\n",
        "            print(\"End of video or cannot read frame.\")\n",
        "            break\n",
        "        # Resize for faster processing\n",
        "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
        "        result = model(frame, agnostic_nms=True)[0]\n",
        "\n",
        "        detections = sv.Detections.from_ultralytics(result)\n",
        "\n",
        "\n",
        "        person_mask = detections.class_id == PERSON_CLASS_ID\n",
        "        detections = detections[person_mask]\n",
        "\n",
        "        person_count = len(detections)\n",
        "\n",
        "        labels = [f\"Person {detections.confidence[i]:.2f}\"\n",
        "                  for i in range(len(detections))]\n",
        "\n",
        "        frame = box_annotator.annotate(\n",
        "            scene=frame,\n",
        "            detections=detections,\n",
        "\n",
        "        )\n",
        "        frame = label_annotator.annotate(scene=frame, detections=detections,labels=labels)\n",
        "         # FPS calculation\n",
        "        curr_time = time.time()\n",
        "        fps = 1 / (curr_time - prev_time)\n",
        "        prev_time = curr_time\n",
        "\n",
        "        cv2.putText(\n",
        "                frame,\n",
        "                f\"Total Persons: {person_count}\",\n",
        "                (20, 40),\n",
        "                cv2.FONT_HERSHEY_COMPLEX,\n",
        "                0.5,\n",
        "                (255, 0, 0),\n",
        "                2\n",
        "            )\n",
        "        cv2.putText(\n",
        "        frame,\n",
        "        f\"FPS: {int(fps)}\",\n",
        "        (20, 80),\n",
        "        cv2.FONT_HERSHEY_COMPLEX,\n",
        "        0.5,\n",
        "        (0, 0,255),\n",
        "        2)\n",
        "        out.write(frame)\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Processing complete! Saved output to {OUTPUT_PATH}\")\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download(\"/content/drive/MyDrive/Colab Notebooks/video/output.mp4\")\n",
        "    print(\"Output File Downloaded\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GymUDVVLGSjH",
        "outputId": "a429623b-0fe4-41e5-ff6b-c4e9ba94e2d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 35 persons, 1 handbag, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 25.6ms\n",
            "Speed: 1.5ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 24.4ms\n",
            "Speed: 1.5ms preprocess, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 23.2ms\n",
            "Speed: 1.5ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 23.2ms\n",
            "Speed: 1.4ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 19.0ms\n",
            "Speed: 1.4ms preprocess, 19.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 17.9ms\n",
            "Speed: 1.4ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 17.6ms\n",
            "Speed: 1.4ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 17.6ms\n",
            "Speed: 2.7ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 14.2ms\n",
            "Speed: 1.4ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 13.8ms\n",
            "Speed: 1.7ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 13.8ms\n",
            "Speed: 1.5ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 13.9ms\n",
            "Speed: 1.5ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 14.3ms\n",
            "Speed: 1.7ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 13.2ms\n",
            "Speed: 1.5ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 13.2ms\n",
            "Speed: 1.5ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 14.0ms\n",
            "Speed: 1.5ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 handbags, 14.7ms\n",
            "Speed: 1.4ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 4 handbags, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 4 handbags, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 14.4ms\n",
            "Speed: 1.4ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 2 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 bird, 1 handbag, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 12.7ms\n",
            "Speed: 1.4ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 4 handbags, 12.6ms\n",
            "Speed: 1.7ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 handbags, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 12.6ms\n",
            "Speed: 1.5ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 4 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 13.5ms\n",
            "Speed: 1.4ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 handbags, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 4 handbags, 12.8ms\n",
            "Speed: 1.4ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 2 handbags, 1 suitcase, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 tennis racket, 13.5ms\n",
            "Speed: 1.5ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 1 skateboard, 1 tennis racket, 18.7ms\n",
            "Speed: 1.5ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 2 handbags, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 13.6ms\n",
            "Speed: 1.5ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 3 handbags, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 12.2ms\n",
            "Speed: 1.5ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 handbags, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 2 handbags, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 handbags, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 2 handbags, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 2 handbags, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 2 handbags, 11.9ms\n",
            "Speed: 1.4ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 2 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 1 tennis racket, 12.4ms\n",
            "Speed: 1.6ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 1 tennis racket, 11.9ms\n",
            "Speed: 1.6ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 2 handbags, 2 tennis rackets, 12.8ms\n",
            "Speed: 1.5ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 3 handbags, 1 tennis racket, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 1 handbag, 1 tennis racket, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 handbags, 1 tennis racket, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 2 tennis rackets, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 1 tennis racket, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 1 tennis racket, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 1 tennis racket, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 backpacks, 3 handbags, 1 tennis racket, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 3 handbags, 1 tennis racket, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 4 handbags, 1 tennis racket, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 5 handbags, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 3 handbags, 1 tennis racket, 12.5ms\n",
            "Speed: 1.7ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 1 suitcase, 1 tennis racket, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 1 tennis racket, 14.8ms\n",
            "Speed: 1.4ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 1 suitcase, 1 tennis racket, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 1 tennis racket, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 5 handbags, 1 tennis racket, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 1 tennis racket, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 1 tennis racket, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 1 handbag, 1 tennis racket, 11.9ms\n",
            "Speed: 1.4ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 1 tennis racket, 12.9ms\n",
            "Speed: 1.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 1 tennis racket, 11.9ms\n",
            "Speed: 1.4ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 3 handbags, 1 tennis racket, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 1 tennis racket, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 13.2ms\n",
            "Speed: 1.5ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 13.5ms\n",
            "Speed: 1.5ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 2 handbags, 1 suitcase, 1 tennis racket, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 1 tennis racket, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 1 tennis racket, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 1 tennis racket, 14.3ms\n",
            "Speed: 3.0ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 1 tennis racket, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 1 tennis racket, 11.9ms\n",
            "Speed: 1.6ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 1 tennis racket, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 1 tennis racket, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 1 tennis racket, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 1 tennis racket, 14.7ms\n",
            "Speed: 1.6ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 1 tennis racket, 15.8ms\n",
            "Speed: 1.5ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 4 handbags, 1 tennis racket, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 1 tennis racket, 11.9ms\n",
            "Speed: 1.4ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 1 tennis racket, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 3 handbags, 1 tennis racket, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 backpack, 3 handbags, 1 tennis racket, 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 12.6ms\n",
            "Speed: 1.4ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 13.9ms\n",
            "Speed: 2.5ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 1 tennis racket, 11.5ms\n",
            "Speed: 1.6ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 1 tennis racket, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 4 handbags, 1 tennis racket, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 1 tennis racket, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 1 tennis racket, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 handbag, 1 tennis racket, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 1 tennis racket, 12.0ms\n",
            "Speed: 1.5ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 1 tennis racket, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 1 tennis racket, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 2 handbags, 1 tennis racket, 21.4ms\n",
            "Speed: 1.5ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 3 handbags, 1 tennis racket, 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 3 handbags, 1 tennis racket, 16.0ms\n",
            "Speed: 1.5ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 1 tennis racket, 23.9ms\n",
            "Speed: 1.5ms preprocess, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 5 handbags, 1 tennis racket, 21.9ms\n",
            "Speed: 2.3ms preprocess, 21.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 1 tennis racket, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 1 tennis racket, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 tennis racket, 12.7ms\n",
            "Speed: 1.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 6 handbags, 1 tennis racket, 13.2ms\n",
            "Speed: 1.4ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 5 handbags, 1 tennis racket, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 handbags, 1 tennis racket, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 5 handbags, 13.9ms\n",
            "Speed: 5.6ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 4 handbags, 17.3ms\n",
            "Speed: 1.4ms preprocess, 17.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 14.8ms\n",
            "Speed: 3.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 5 handbags, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 12.9ms\n",
            "Speed: 1.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 backpack, 1 handbag, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 13.7ms\n",
            "Speed: 1.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 16.5ms\n",
            "Speed: 1.4ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 12.9ms\n",
            "Speed: 4.0ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 22.8ms\n",
            "Speed: 1.5ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 22.1ms\n",
            "Speed: 3.9ms preprocess, 22.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 5 handbags, 18.0ms\n",
            "Speed: 1.4ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 14.1ms\n",
            "Speed: 1.6ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 18.6ms\n",
            "Speed: 1.5ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 21.3ms\n",
            "Speed: 1.7ms preprocess, 21.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 17.1ms\n",
            "Speed: 1.5ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 3 handbags, 18.8ms\n",
            "Speed: 1.6ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 27.8ms\n",
            "Speed: 2.6ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 16.3ms\n",
            "Speed: 1.5ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 23.3ms\n",
            "Speed: 1.5ms preprocess, 23.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 14.0ms\n",
            "Speed: 1.5ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 13.9ms\n",
            "Speed: 1.5ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 13.6ms\n",
            "Speed: 1.6ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 16.3ms\n",
            "Speed: 1.5ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 14.0ms\n",
            "Speed: 1.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 1 tennis racket, 19.7ms\n",
            "Speed: 3.5ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 18.4ms\n",
            "Speed: 1.5ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 1 tennis racket, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 1 tennis racket, 20.3ms\n",
            "Speed: 2.9ms preprocess, 20.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 1 tennis racket, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 1 tennis racket, 15.2ms\n",
            "Speed: 1.4ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 1 tennis racket, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 1 tennis racket, 19.4ms\n",
            "Speed: 1.4ms preprocess, 19.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 1 tennis racket, 14.7ms\n",
            "Speed: 1.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 1 tennis racket, 14.8ms\n",
            "Speed: 1.5ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 15.4ms\n",
            "Speed: 3.5ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 3 handbags, 1 tennis racket, 14.1ms\n",
            "Speed: 1.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 14.1ms\n",
            "Speed: 1.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 19.3ms\n",
            "Speed: 5.8ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 20.2ms\n",
            "Speed: 1.4ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 14.3ms\n",
            "Speed: 1.5ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 1 clock, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 16.5ms\n",
            "Speed: 3.8ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 20.0ms\n",
            "Speed: 1.5ms preprocess, 20.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 17.4ms\n",
            "Speed: 3.6ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 15.0ms\n",
            "Speed: 1.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 3 handbags, 20.2ms\n",
            "Speed: 1.4ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 2 handbags, 15.3ms\n",
            "Speed: 1.4ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 3 handbags, 19.0ms\n",
            "Speed: 1.6ms preprocess, 19.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 5 handbags, 1 tennis racket, 14.9ms\n",
            "Speed: 1.6ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 3 handbags, 1 tennis racket, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 3 handbags, 1 tennis racket, 15.3ms\n",
            "Speed: 1.5ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 backpacks, 5 handbags, 1 tennis racket, 22.2ms\n",
            "Speed: 1.5ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 2 backpacks, 5 handbags, 1 suitcase, 19.4ms\n",
            "Speed: 1.5ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 2 backpacks, 5 handbags, 23.4ms\n",
            "Speed: 1.4ms preprocess, 23.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 4 handbags, 14.9ms\n",
            "Speed: 1.5ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 4 handbags, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 4 handbags, 24.5ms\n",
            "Speed: 4.0ms preprocess, 24.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 4 handbags, 1 tennis racket, 21.0ms\n",
            "Speed: 1.5ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 4 handbags, 1 tennis racket, 15.6ms\n",
            "Speed: 1.7ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 2 handbags, 1 tennis racket, 18.6ms\n",
            "Speed: 1.5ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 1 tennis racket, 19.2ms\n",
            "Speed: 1.5ms preprocess, 19.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 1 tennis racket, 16.3ms\n",
            "Speed: 1.6ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 1 tennis racket, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 1 handbag, 15.4ms\n",
            "Speed: 1.5ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 backpacks, 3 handbags, 15.7ms\n",
            "Speed: 5.1ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 backpack, 2 handbags, 16.4ms\n",
            "Speed: 1.5ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 backpack, 3 handbags, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 18.5ms\n",
            "Speed: 1.6ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 19.0ms\n",
            "Speed: 5.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 2 handbags, 1 tennis racket, 18.6ms\n",
            "Speed: 1.5ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 2 handbags, 15.6ms\n",
            "Speed: 1.4ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 2 handbags, 1 tennis racket, 16.2ms\n",
            "Speed: 1.4ms preprocess, 16.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 1 tennis racket, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 1 tennis racket, 15.6ms\n",
            "Speed: 1.4ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 5 handbags, 1 tennis racket, 15.9ms\n",
            "Speed: 1.4ms preprocess, 15.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 1 umbrella, 5 handbags, 15.6ms\n",
            "Speed: 1.4ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 1 umbrella, 3 handbags, 1 tennis racket, 15.6ms\n",
            "Speed: 1.5ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 1 umbrella, 4 handbags, 15.6ms\n",
            "Speed: 1.5ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 16.6ms\n",
            "Speed: 1.6ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 2 handbags, 15.5ms\n",
            "Speed: 1.4ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 1 handbag, 1 tennis racket, 14.9ms\n",
            "Speed: 1.5ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 4 handbags, 1 tennis racket, 13.7ms\n",
            "Speed: 1.4ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 handbags, 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 1 handbag, 13.5ms\n",
            "Speed: 1.4ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 backpacks, 2 handbags, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 2 handbags, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 backpacks, 3 handbags, 14.4ms\n",
            "Speed: 1.5ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 backpacks, 3 handbags, 13.3ms\n",
            "Speed: 1.4ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 3 handbags, 13.6ms\n",
            "Speed: 1.4ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 1 tennis racket, 13.2ms\n",
            "Speed: 1.3ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 1 tennis racket, 13.2ms\n",
            "Speed: 1.3ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 14.0ms\n",
            "Speed: 1.5ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 1 tennis racket, 13.3ms\n",
            "Speed: 1.7ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 2 handbags, 1 tennis racket, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 3 handbags, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 5 handbags, 1 tennis racket, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 4 handbags, 1 tennis racket, 13.3ms\n",
            "Speed: 1.4ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 1 tennis racket, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 1 tennis racket, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 1 tennis racket, 13.0ms\n",
            "Speed: 1.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 5 handbags, 1 tennis racket, 13.0ms\n",
            "Speed: 1.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 13.5ms\n",
            "Speed: 1.4ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 handbag, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 backpack, 2 handbags, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 13.0ms\n",
            "Speed: 1.6ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 1 tennis racket, 15.0ms\n",
            "Speed: 1.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 1 handbag, 19.3ms\n",
            "Speed: 1.5ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 13.0ms\n",
            "Speed: 1.5ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 12.8ms\n",
            "Speed: 1.3ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 2 handbags, 12.6ms\n",
            "Speed: 1.4ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 12.8ms\n",
            "Speed: 1.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 12.5ms\n",
            "Speed: 1.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 3 handbags, 13.4ms\n",
            "Speed: 1.5ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 backpacks, 2 handbags, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 12.2ms\n",
            "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 backpacks, 3 handbags, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 12.5ms\n",
            "Speed: 1.4ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 1 handbag, 14.7ms\n",
            "Speed: 1.4ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 backpacks, 1 handbag, 12.7ms\n",
            "Speed: 1.4ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 backpacks, 2 handbags, 13.9ms\n",
            "Speed: 1.4ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 1 suitcase, 20.1ms\n",
            "Speed: 1.5ms preprocess, 20.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 13.3ms\n",
            "Speed: 1.4ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 2 handbags, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 1 handbag, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 umbrella, 2 handbags, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 umbrella, 3 handbags, 13.6ms\n",
            "Speed: 1.3ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 3 handbags, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 12.4ms\n",
            "Speed: 1.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 2 handbags, 11.8ms\n",
            "Speed: 1.6ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 11.7ms\n",
            "Speed: 1.3ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 13.2ms\n",
            "Speed: 1.5ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "End of video or cannot read frame.\n",
            "Processing complete! Saved output to /content/drive/MyDrive/Colab Notebooks/video/output.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7b64e0c0-1bd7-459c-b3f2-d25a8bd887a6\", \"output.mp4\", 9977988)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output File Downloaded\n"
          ]
        }
      ]
    }
  ]
}